Tokenisation Report
Sentence:
The cat sat on the mat because it was tired.

1. BPE (GPT-2)
Tokens:  ['The', 'Ä cat', 'Ä sat', 'Ä on', 'Ä the', 'Ä mat', 'Ä because', 'Ä it', 'Ä was', 'Ä tired', '.']
Token IDs: [464, 3797, 3332, 319, 262, 2603, 780, 340, 373, 10032, 13]
Total Tokens: 11


2. WordPiece (BERT)
Tokens:  ['the', 'cat', 'sat', 'on', 'the', 'mat', 'because', 'it', 'was', 'tired', '.']
Token IDs: [1996, 4937, 2938, 2006, 1996, 13523, 2138, 2009, 2001, 5458, 1012]
Total Tokens: 11

3. SentencePiece (T5)
Tokens:  ['â–The', 'â–cat', 'â–', 's', 'at', 'â–on', 'â–the', 'â–mat', 'â–because', 'â–it', 'â–was', 'â–tired', '.']
Token IDs: [37, 1712, 3, 7, 144, 30, 8, 6928, 250, 34, 47, 7718, 5]
Total Tokens: 13

ğŸ“ Why the splits differ:
Different tokenizers use different vocabulary and algorithms:

BPE merges frequent subwords (e.g., ti, red â†’ tired)

WordPiece adds ## for subword joins (##ing, ##ly)

SentencePiece treats space as a token (e.g., â–The)

Each model has its own "vocabulary dictionary", affecting how it chunks words.

ğŸ§  Fill-in-the-Blank Predictions (BERT)
Original sentence:
The cat sat on the [MASK] because it was [MASK].

ğŸ”¹ First [MASK]:
floor (0.2534)

couch (0.0875)

bed (0.0874)

ğŸ”¹ Second [MASK]:
cold (0.0537)

hungry (0.0453)

warm (0.0316)

ğŸ“ Plausibility Notes:
BERTâ€™s predictions are contextually strong:

For "sat on the", options like floor, bed, couch are realistic.

For "because it was", words like cold, hungry, warm fit a catâ€™s state.

The model reflects real-world language usage it learned from training on Wikipedia and books.